{
  data_module: {
    type: map
    setup: {
      col_id: client_id
      dataset_files: {
        data_path: "data/train_trx_file.parquet"
      }
      split_by: files
      valid_size: 0.05
      valid_split_seed: 42
    }
    train: {
      min_seq_len: 25
      augmentations: [
        [DropoutTrx, {trx_dropout: 0.01}]
      ]
      split_strategy: {
        split_strategy: "SampleSlices"
        split_count: 5
        cnt_min: 25
        cnt_max: 200
      }
      num_workers: 16
      batch_size: 64
    }
    valid: {
      augmentations: []
      split_strategy: {
        split_strategy: SampleSlices
        split_count: 5
        cnt_min: 25
        cnt_max: 100
      }
      num_workers: 16
      batch_size: 512
    }
  }

  seed_everything: 42
  trainer: {
    gpus: 1
    auto_select_gpus: false

    max_epochs: 60

    checkpoint_callback: false
    deterministic: true
  }
  logger_name: transformer_model

  params: {
    data_module_class: dltranz.data_load.data_module.coles_data_module.ColesDataModuleTrain
    pl_module_class: dltranz.lightning_modules.coles_module.CoLESModule

    validation_metric_params: {
        K: 4
        metric: cosine
    }

    encoder_type: transf
    transf: {
      train_starter: true
      shared_layers: false
      input_size: 256
      n_heads: 8
      dim_hidden: 256
      dropout: 0.1
      n_layers: 6
      use_positional_encoding: false
      max_seq_len: 1200
      use_after_mask: false
      use_src_key_padding_mask: false
    }

    trx_encoder: {
      norm_embeddings: false
      embeddings_noise: 0.003
      embeddings: {
        trans_date: {in: 800, out: 16}
        small_group: {in: 250, out: 16}
      }
      numeric_values: {
        amount_rur: identity
      }
    }
    
    lr_scheduler: {
      step_size: 1000
      step_gamma: 1
      "warmup": {
        num_warmup_steps: 20
        num_training_steps: 60
      }
    }

    head_layers: [
      [BatchNorm1d, {num_features: "{seq_encoder.embedding_size}"}]
      [NormEncoder, {}]
    ]

    train: {
      swa: false
      sampling_strategy: HardNegativePair
      # gradient_clip_val: 1
      neg_count: 5
      loss: ContrastiveLoss
      margin: 0.5
      lr: 0.001
      weight_decay: 0.0
    } 
    
  }

  model_path: "models/transf_model.p"

  inference_dataloader: {
    col_id: client_id
    dataset_files: [
      "data/train_trx_file.parquet"
      "data/test_trx_file.parquet"
    ]
    SeqLenLimit: {max_seq_len: 1600}
    loader: {
      num_workers: 4
      batch_size: 64
    }
  }

  output: {
    path: data/transf_embeddings
    format: pickle
  }
}
